= How to monitor my compute instance in GCP?
//:docinfo: shared
//:imagesdir: images
//:stylesheet: elastic_training.css
:toc: left
:toc-title:
:field_guide: tutorial

In this {field_guide} you will see how to monitor your GCP compute Engine.

== Service Account setup

GCP implements link:https://cloud.google.com/compute/docs/access/service-accounts[service accounts, window=_blank] as a way to securely access APIs. In order to monitor GCP with Elastic we will need a service account. The easiest way is to use a predefined service account that GCP link:https://cloud.google.com/compute/docs/access/service-accounts?hl=en#default_service_account[creates automatically, window=_blank]. Alternatively we can create a new service account. In this {field_guide}, we will create a new one:

First, we will access the service account menu by clicking on _Menu -> IAM & Admin -> Service Accounts_.

image:images/service_account_menu.png[width=50%]

Next, we will click on _Create Service Account_. Then, we will define the new service account name as _gcp-monitor_ and the description as "Service account to monitor GCP services using the Elastic Stack".

image:images/service_account_name.png[width=50%]

[IMPORTANT]
====
This next step is very important, so make sure to click on the correct roles.
====

In order to monitor our GCP services we need to add two main roles to the service account:

_Compute Viewer_:

image:images/service_account_roles_compute_viewer.png[width=50%]

_Monitoring Viewer_:

image:images/service_account_roles_monitoring_viewer.png[width=50%]

The final result should be the following:

image:images/service_account_roles_final.png[width=50%]

Click on Continue, then skip granting users access to this service. Finally, click _DONE_ and our service account will be ready to be used.

Next, in order to use the service account we need to click on create keys and create the JSON key type.
image:images/service_account_create_key.png[width=50%]

Clicking on create key downloads the credential file. We will keep this file in a accessible place to use later.


== Elastic Stack setup

In order to monitor GCP using the Elastic Stack we need two main components: an Elastic deployment to store and analyze the data and an agent to collect and ship the data.

[NOTE]
====
In this {field_guide} we assume the Elastic cluster is already running and ready to be used. Make sure you have your *cloudid* and your credentials in hand.
====

There are two agents that can be used to monitor GCP. We will use Metricbeat to monitor metrics and Filebeat to monitor logs. We could run the monitor agent in any machine, but in this {field_guide} we will use a small GCP instance, e2-small (2 vCPUs, 2 GB memory), with an Ubuntu distribution. After starting and connecting to the agent instance, we will download and configure the agent.

[source, role=bash]
----
wget https://artifacts.elastic.co/downloads/beats/metricbeat/metricbeat-7.9.2-linux-x86_64.tar.gz
tar metricbeat-7.9.2-linux-x86_64.tar.gz
----

First, we will configure and test the output. Edit `metricbeat-7.9.2-linux-x86_64/metricbeat.yml` and add the following lines to the end of the file.
[source, role=bash]
----
cloud.id: "${CLOUD_ID}"
cloud.auth: "${ES_PWD}"
----
Next, we will create the keystore to securely store our credentials.
[source, role=bash]
----
./metricbeat keystore create
----

Run the command below and then paste the cloud id we kept in hand as suggested earlier.
[source, role=bash]
----
./metricbeat keystore add CLOUD_ID
----

Next, we will add the credentials to the keystore by running the command below and inserting `elastic:<password>`, where `<password>` is our cluster password.
[source, role=bash]
----
./metricbeat keystore add ES_PWD
----

Finally, we will test if the configuration is working. If it is not working, verify if you used the right credentials and add them again.
[source, role=bash]
----
./metricbeat test output
----

Now that the output is working we are going to setup the input (GCP).

== GCP Compute

In order to collect metrics from GCP, we will use the link:https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-module-googlecloud.html[Google Cloud Platform, window=_blank] module. This module periodically fetches monitoring metrics from Google Cloud Platform using link:https://cloud.google.com/monitoring/api/metrics_gcp[Stackdriver Monitoring API, window=_blank] for Google Cloud Platform services.

[WARNING]
====
Extra GCP charges on Stackdriver Monitoring API requests may be generated by this module. Please see link:https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-module-googlecloud.html#gcp-api-requests[rough estimation of the number of API calls, window=_blank] for more details.
====

First, enable the GCP module.
[source, role=bash]
----
./metricbeat enable googlecloud
----

Next, we will edit the `modules.d/googlecloud.yml` file to configure which metrics do we want to collect.
[source]
----
- module: googlecloud
  metricsets:
    - compute
  zone: ""
  project_id: "elastic-education"
  period: 1m
  credentials_file_path: "/home/ubuntu/metricbeat-7.9.2-linux-x86_64/credentials.json"
----

Note that we are using the `compute` metricset which is a predefined metricset that collects some GCP compute metrics. We are collecting data from all zones within the `elastic-education` project-id. Finally, the `credentials_file_path` is the path to the credentials file that we have generated earlier (don't forget to create the file if it does not exist and to use the correct full path).

Now, we can simply test the input and check if the data is being collected.
[source, role=bash]
----
./metricbeat test input
----

Input and output ready. Next we will setup Kibana (this might take a few minutes) and start loading the data.
[source, role=bash]
----
./metricbeat setup
./metricbeat -e
----

Finally, go to Kibana and open the "[Metricbeat Googlecloud] Compute Overview" dashboard.
image:images/gcp_compute_overview_dashboard.png[width=50%]

== Bigquery

== Bigtable
